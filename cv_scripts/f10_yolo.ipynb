{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('base': conda)"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "4dca466a4408c2c8e057a29a692c96cf1a4e165c069ca20a87fbf7ccbb27afbf"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect colab to your google drive"
      ],
      "metadata": {
        "id": "mHbNxdP6eLd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Connect to your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "outputs": [],
      "metadata": {
        "id": "PYICcmTfdm0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "cd /content/drive/My Drive/ese516"
      ],
      "outputs": [],
      "metadata": {
        "id": "-JhXPEc7aYvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip f110_dataset_20220209.zip"
      ],
      "metadata": {
        "id": "Mj-Uw_k2lsg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Useful tools:"
      ],
      "metadata": {
        "id": "pw-yUtFqiNFR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import torch.nn as nn\n",
        "\n",
        "def DisplayImage(img):\n",
        "    image = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
        "    # fig, ax = plt.subplots(1, figsize=(6, 8))\n",
        "    # image = np.transpose(image.copy(), (1, 2, 0))\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(image)\n",
        "    plt.show()\n",
        "\n",
        "def DisplayLabel(img, bboxs):\n",
        "    # image = np.transpose(image.copy(), (1, 2, 0))\n",
        "    # fig, ax = plt.subplots(1, figsize=(6, 8))\n",
        "    image = cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)\n",
        "    fig, ax = plt.subplots(1)\n",
        "    edgecolor = [1, 0, 0]\n",
        "    if len(bboxs) == 1:\n",
        "        bbox = bboxs[0]\n",
        "        ax.add_patch(patches.Rectangle((bbox[0] - bbox[2]/2, bbox[1] - bbox[3]/2), bbox[2], bbox[3], linewidth=1, edgecolor=edgecolor, facecolor='none'))\n",
        "    elif len(bboxs) > 1:\n",
        "        for bbox in bboxs:\n",
        "            ax.add_patch(patches.Rectangle((bbox[0] - bbox[2]/2, bbox[1] - bbox[3]/2), bbox[2], bbox[3], linewidth=1, edgecolor=edgecolor, facecolor='none'))\n",
        "    ax.imshow(image)\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "He2Gh1rRHJ1q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data:"
      ],
      "metadata": {
        "id": "mnD5DQ5Q0PgF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dataset_folder = 'f110_dataset_20220209/'\n",
        "path = dataset_folder + \"labels.npy\"\n",
        "labels = np.load(path)\n",
        "print(len(labels))"
      ],
      "outputs": [],
      "metadata": {
        "id": "olXIi9MjUEOt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "final_dim = [5, 10]\n",
        "input_dim = [180, 320]\n",
        "anchor_size = [(input_dim[0] / final_dim[0]), (input_dim[1] / final_dim[1])]\n",
        "arr = np.arange(labels.shape[0])\n",
        "np.random.shuffle(arr)\n",
        "\n",
        "# convert feature map coord to image coord\n",
        "def grid_cell(cell_indx, cell_indy):\n",
        "    stride_0 = anchor_size[1]\n",
        "    stride_1 = anchor_size[0]\n",
        "    return np.array([cell_indx * stride_0, cell_indy * stride_1, cell_indx * stride_0 + stride_0, cell_indy * stride_1 + stride_1])\n",
        "\n",
        "# convert from [c_x, c_y, w, h] to [x_l, y_l, x_r, y_r]\n",
        "def bbox_convert(c_x, c_y, w, h):\n",
        "    return [c_x - w/2, c_y - h/2, c_x + w/2, c_y + h/2]\n",
        "\n",
        "# convert from [x_l, y_l, x_r, x_r] to [c_x, c_y, w, h]\n",
        "def bbox_convert_r(x_l, y_l, x_r, y_r):\n",
        "    return [x_l/2 + x_r/2, y_l/2 + y_r/2, x_r - x_l, y_r - y_l]\n",
        "\n",
        "# calculating IoU\n",
        "def IoU(a, b):\n",
        "    # referring to IoU algorithm in slides\n",
        "    inter_w = max(0, min(a[2], b[2]) - max(a[0], b[0]))\n",
        "    inter_h = max(0, min(a[3], b[3]) - max(a[1], b[1]))\n",
        "    inter_ab = inter_w * inter_h\n",
        "    area_a = (a[3] - a[1]) * (a[2] - a[0])\n",
        "    area_b = (b[3] - b[1]) * (b[2] - b[0])\n",
        "    union_ab = area_a + area_b - inter_ab\n",
        "    return inter_ab / union_ab\n",
        "\n",
        "def assign_label(label):\n",
        "    label_gt = np.zeros((5, final_dim[0], final_dim[1]))\n",
        "    IoU_threshold = 0.01\n",
        "    IoU_max = 0\n",
        "    IoU_max_ind = [0, 0]\n",
        "\n",
        "    for ind_row in range(final_dim[0]):\n",
        "        for ind_col in range(final_dim[1]):\n",
        "            label_assign = 0\n",
        "            grid_info = grid_cell(ind_col, ind_row)\n",
        "            label_bbox = bbox_convert(label[0], label[1], label[2], label[3])\n",
        "            IoU_value = IoU(label_bbox, grid_info)\n",
        "            if IoU_value > IoU_threshold:\n",
        "                label_assign = 1\n",
        "            if IoU_value > IoU_max:\n",
        "                IoU_max = IoU_value\n",
        "                IoU_max_ind[0] = ind_row\n",
        "                IoU_max_ind[1] = ind_col\n",
        "\n",
        "            # construct the gt vector\n",
        "            if label_assign == 1:\n",
        "                label_gt[0, ind_row, ind_col] = 1\n",
        "                label_gt[1, ind_row, ind_col] = label[0] - (grid_info[0] + anchor_size[1]/2)\n",
        "                label_gt[2, ind_row, ind_col] = label[1] - (grid_info[1] + anchor_size[0]/2)\n",
        "                label_gt[3, ind_row, ind_col] = label[2] / float(input_dim[1])\n",
        "                label_gt[4, ind_row, ind_col] = label[3] / float(input_dim[0])\n",
        "\n",
        "    grid_info = grid_cell(IoU_max_ind[0], IoU_max_ind[1])\n",
        "    label_gt[0, IoU_max_ind[0], IoU_max_ind[1]] = 1\n",
        "    label_gt[1, IoU_max_ind[0], IoU_max_ind[1]] = label[0] - (grid_info[0] + anchor_size[1]/2)\n",
        "    label_gt[2, IoU_max_ind[0], IoU_max_ind[1]] = label[1] - (grid_info[1] + anchor_size[0]/2)\n",
        "    label_gt[3, IoU_max_ind[0], IoU_max_ind[1]] = label[2] / float(input_dim[1])\n",
        "    label_gt[4, IoU_max_ind[0], IoU_max_ind[1]] = label[3] / float(input_dim[0])\n",
        "    return label_gt\n",
        "\n",
        "# Due to the small size of dataset, we preprocess them into memory to speed up training.\n",
        "images = []\n",
        "for ind in range(labels.shape[0]):\n",
        "    img_path = dataset_folder + str(ind) + '.jpg'\n",
        "    img = cv2.imread(img_path) / 255.0\n",
        "    img = cv2.resize(img, (input_dim[1], input_dim[0]))\n",
        "    images.append(img)\n",
        "\n",
        "# Construct datasets\n",
        "class F110Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, scope, folder, labels):\n",
        "        self.folder = folder\n",
        "        self.labels = labels\n",
        "        self.data_ind1 = (np.floor(self.labels.shape[0] / 10) * scope[0]).astype(int)\n",
        "        self.data_ind2 = (np.floor(self.labels.shape[0] / 10) * scope[1]).astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data_ind2 - self.data_ind1\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        label = self.labels[arr[index]].copy() / (360.0 / input_dim[0])\n",
        "        label_gt = np.asarray(assign_label(label))\n",
        "        img_np = images[arr[index]]\n",
        "        img_np = np.transpose(img_np, (2, 0, 1))\n",
        "\n",
        "        return torch.from_numpy(img_np).type('torch.FloatTensor'), \\\n",
        "                torch.from_numpy(label_gt).type('torch.FloatTensor'), label\n",
        "\n",
        "train_set = F110Dataset([0, 9.5], dataset_folder, labels)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=1, shuffle=True)\n",
        "validation_set = F110Dataset([9.5, 10], dataset_folder, labels)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset=validation_set, batch_size=1, shuffle=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "mi0aYpBzbuGj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Plot one label to see if it's correct.\n",
        "\n",
        "for data_ind, data_list in enumerate(train_loader):\n",
        "    if data_ind == 0:\n",
        "        image = data_list[0]\n",
        "        label_gt = data_list[1]\n",
        "        label = data_list[2]\n",
        "        break\n",
        "print(image[0].numpy().shape)\n",
        "print(label[0])\n",
        "print(label_gt[0][0])\n",
        "print(label)\n",
        "DisplayLabel(np.transpose(image[0].numpy(), (1, 2, 0)), label)"
      ],
      "outputs": [],
      "metadata": {
        "id": "AuQdedylVPSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "zDRbZRAsh7km"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class F110_YOLO(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(F110_YOLO, self).__init__()\n",
        "        # TODO: Change the channel depth of each layer\n",
        "        self.conv1 = nn.Conv2d(3, 4, kernel_size = 4, padding = 1, stride = 2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(4)\n",
        "        self.relu1 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(4, 5, kernel_size = 4, padding = 1, stride = 2)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(5)\n",
        "        self.relu2 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(5, 6, kernel_size = 4, padding = 1, stride = 2)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(6)\n",
        "        self.relu3 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(6, 7, kernel_size = 4, padding = 1, stride = 2)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(7)\n",
        "        self.relu4 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(7, 8, kernel_size = 4, padding = 1, stride = 2)\n",
        "        self.batchnorm5 = nn.BatchNorm2d(8)\n",
        "        self.relu5 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv6 = nn.Conv2d(8, 7, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.batchnorm6 = nn.BatchNorm2d(7)\n",
        "        self.relu6 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv7 = nn.ConvTranspose2d(7, 6, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.batchnorm7 = nn.BatchNorm2d(6)\n",
        "        self.relu7 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv8 = nn.ConvTranspose2d(6, 6, kernel_size = 3, padding = 1, stride = 1)\n",
        "        self.batchnorm8 = nn.BatchNorm2d(6)\n",
        "        self.relu8 = nn.ReLU(inplace = True)\n",
        "\n",
        "        self.conv9 = nn.Conv2d(6, 5, kernel_size = 1, padding = 0, stride = 1)\n",
        "        self.relu9 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        debug = 0 # change this to 1 if you want to check network dimensions\n",
        "        if debug == 1: print(0, x.shape)\n",
        "        x = torch.relu(self.batchnorm1(self.conv1(x)))\n",
        "        if debug == 1: print(1, x.shape)\n",
        "        x = torch.relu(self.batchnorm2(self.conv2(x)))\n",
        "        if debug == 1: print(2, x.shape)\n",
        "        x = torch.relu(self.batchnorm3(self.conv3(x)))\n",
        "        if debug == 1: print(3, x.shape)\n",
        "        x = torch.relu(self.batchnorm4(self.conv4(x)))\n",
        "        if debug == 1: print(4, x.shape)\n",
        "        x = torch.relu(self.batchnorm5(self.conv5(x)))\n",
        "        if debug == 1: print(5, x.shape)\n",
        "        x = torch.relu(self.batchnorm6(self.conv6(x)))\n",
        "        if debug == 1: print(6, x.shape)\n",
        "        x = torch.relu(self.batchnorm7(self.conv7(x)))\n",
        "        if debug == 1: print(7, x.shape)\n",
        "        x = torch.relu(self.batchnorm8(self.conv8(x)))\n",
        "        if debug == 1: print(8, x.shape)\n",
        "        x = self.conv9(x)\n",
        "        if debug == 1: print(9, x.shape)\n",
        "        x = torch.cat([x[:, 0:3, :, :], torch.sigmoid(x[:, 3:5, :, :])], dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def get_loss(self, result, truth, lambda_coord = 5, lambda_noobj = 1):\n",
        "        x_loss = (result[:, 1, :, :] - truth[:, 1, :, :]) ** 2\n",
        "        y_loss = (result[:, 2, :, :] - truth[:, 2, :, :]) ** 2\n",
        "        w_loss = (torch.sqrt(result[:, 3, :, :]) - torch.sqrt(truth[:, 3, :, :])) ** 2\n",
        "        h_loss = (torch.sqrt(result[:, 4, :, :]) - torch.sqrt(truth[:, 4, :, :])) ** 2\n",
        "        class_loss_obj = truth[:, 0, :, :] * (truth[:, 0, :, :] - result[:, 0, :, :]) ** 2\n",
        "        class_loss_noobj = (1 - truth[:, 0, :, :]) * lambda_noobj * (truth[:, 0, :, :] - result[:, 0, :, :]) ** 2\n",
        "\n",
        "        total_loss = torch.sum(lambda_coord * truth[:, 0, :, :] * (x_loss + y_loss + w_loss + h_loss) + class_loss_obj + class_loss_noobj)\n",
        "\n",
        "        return total_loss\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "MhdF7_Flurny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train your network\n",
        "\n",
        "Save checkpoints and reload from the most recent. This is due to time constraints inside of colab."
      ],
      "metadata": {
        "id": "EvNh3B3FiAPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Begin training the model\n",
        "train_loss_record = []\n",
        "validation_loss_record = []\n",
        "device = torch.device('cuda')\n",
        "model = F110_YOLO().to(device)"
      ],
      "outputs": [],
      "metadata": {
        "id": "lr3E962T0PgL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Training Process\n",
        "batch_size = 1 # TODO: What batchsize is good? 1? 10? 100?\n",
        "epochs = 1 # TODO: How many times should we train? 1? 10? 100?\n",
        "lr = 1 # TODO: What learning rate is good? 1? 0.1? 0.01?\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    validation_loss = []\n",
        "    # ind = 0\n",
        "\n",
        "    time_train = 0\n",
        "    for image_t, label_t, _ in train_loader:\n",
        "        image_t = image_t.to(device)\n",
        "        label_t = label_t.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        result = model(image_t)\n",
        "        loss = model.get_loss(result, label_t)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item()/batch_size)\n",
        "    train_loss_record.append(np.average(train_loss))\n",
        "\n",
        "    ## validationing\n",
        "    model.eval()\n",
        "    object_in_class = 0\n",
        "    truth_in_class = 0\n",
        "    for image_t, label_t, _ in validation_loader:\n",
        "        image_t = image_t.to(device)\n",
        "        label_t = label_t.to(device)\n",
        "        result = model(image_t)\n",
        "        loss = model.get_loss(result, label_t)\n",
        "        validation_loss.append(loss.item())\n",
        "\n",
        "    validation_loss_record.append(np.average(validation_loss))\n",
        "    print(\"total epoch:\", len(train_loss_record), '| train_loss:', np.average(train_loss), '| validation_loss:', np.average(validation_loss), )\n",
        "\n",
        "# save the model\n",
        "model_save_name = 'model_{}.pt'.format(len(train_loss_record))\n",
        "path = \"\" + model_save_name\n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "from tempfile import TemporaryFile\n",
        "path = \"loss_{}.npy\".format(len(train_loss_record))\n",
        "outfile = TemporaryFile()\n",
        "np.save(path, [np.array(train_loss_record), np.array(validation_loss_record)])"
      ],
      "outputs": [],
      "metadata": {
        "id": "hQuOI_n_iEiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Plot loss curves\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(range(len(train_loss_record)), train_loss_record, range(len(validation_loss_record)), validation_loss_record)\n",
        "ax.set_yscale('log')\n",
        "ax.set_title('Training and validationing Error')\n",
        "plt.show()\n",
        "print(validation_loss_record[-1:])\n",
        "print(train_loss_record[-1:])"
      ],
      "outputs": [],
      "metadata": {
        "id": "0z3xqlwx0PgL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Converting label to bounding boxes\n",
        "\n",
        "def label_to_box_xyxy(result, threshold = 0.9):\n",
        "    validation_result = []\n",
        "    result_prob = []\n",
        "    for ind_row in range(final_dim[0]):\n",
        "        for ind_col in range(final_dim[1]):\n",
        "            grid_info = grid_cell(ind_col, ind_row)\n",
        "            validation_result_cell = []\n",
        "            if result[0, ind_row, ind_col] >= threshold:\n",
        "                c_x = grid_info[0] + anchor_size[1]/2 + result[1, ind_row, ind_col]\n",
        "                c_y = grid_info[1] + anchor_size[0]/2 + result[2, ind_row, ind_col]\n",
        "                w = result[3, ind_row, ind_col] * input_dim[1]\n",
        "                h = result[4, ind_row, ind_col] * input_dim[0]\n",
        "                x1, y1, x2, y2 = bbox_convert(c_x, c_y, w, h)\n",
        "                x1 = np.clip(x1, 0, input_dim[1])\n",
        "                x2 = np.clip(x2, 0, input_dim[1])\n",
        "                y1 = np.clip(y1, 0, input_dim[0])\n",
        "                y2 = np.clip(y2, 0, input_dim[0])\n",
        "                validation_result_cell.append(x1)\n",
        "                validation_result_cell.append(y1)\n",
        "                validation_result_cell.append(x2)\n",
        "                validation_result_cell.append(y2)\n",
        "                result_prob.append(result[0, ind_row, ind_col])\n",
        "                validation_result.append(validation_result_cell)\n",
        "    validation_result = np.array(validation_result)\n",
        "    result_prob = np.array(result_prob)\n",
        "    return validation_result, result_prob\n",
        "\n",
        "\n",
        "def voting_suppression(result_box, iou_threshold = 0.5):\n",
        "    votes = np.zeros(result_box.shape[0])\n",
        "    for ind, box in enumerate(result_box):\n",
        "        for box_validation in result_box:\n",
        "            if IoU(box_validation, box) > iou_threshold:\n",
        "                votes[ind] += 1\n",
        "    return (-votes).argsort()\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "bz2f0EtJoJ4J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Display some images in the validation set\n",
        "\n",
        "# validation_loader = torch.utils.data.DataLoader(dataset=validation_set, batch_size=1, shuffle=False)\n",
        "for data_ind, data_list in enumerate(validation_loader):\n",
        "    image = data_list[0]\n",
        "    label_gt = data_list[1]\n",
        "    label = data_list[2]\n",
        "    if data_ind == 5:\n",
        "        break\n",
        "\n",
        "    # display groud truth\n",
        "    DisplayLabel(np.transpose(image[0].numpy(), (1, 2, 0)), label)\n",
        "\n",
        "    # display detection\n",
        "    voting_iou_threshold = 0.5\n",
        "    confi_threshold = 0.4\n",
        "\n",
        "    image_t = image.to(device)\n",
        "    label_gt_t = label_gt.to(device)\n",
        "    result = model(image_t)\n",
        "    result = result.detach().cpu().numpy()\n",
        "    bboxs, result_prob = label_to_box_xyxy(result[0], confi_threshold)\n",
        "    vote_rank = voting_suppression(bboxs, voting_iou_threshold)\n",
        "    bbox = bboxs[vote_rank[0]]\n",
        "    [c_x, c_y, w, h] = bbox_convert_r(bbox[0], bbox[1], bbox[2], bbox[3])\n",
        "    bboxs_2 = np.array([[c_x, c_y, w, h]])\n",
        "    DisplayLabel(np.transpose(image[0].numpy(), (1, 2, 0)), bboxs_2)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "kdjtDyumfM_V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Calculate accuracy\n",
        "\n",
        "model.eval()\n",
        "object_in_class = 0\n",
        "truth_in_class = 0\n",
        "voting_iou_threshold = 0.5\n",
        "confi_threshold = 0.5\n",
        "\n",
        "for data_ind, data_list in enumerate(validation_loader):\n",
        "    # print(data_ind)\n",
        "\n",
        "    image = data_list[0]\n",
        "    label_gt = data_list[1]\n",
        "    label = data_list[2]\n",
        "\n",
        "    result = model(image.to(device))\n",
        "    result = result.detach().cpu().numpy()\n",
        "    bboxs, result_prob = label_to_box_xyxy(result[0], confi_threshold)\n",
        "    vote_rank = voting_suppression(bboxs, voting_iou_threshold)\n",
        "    bbox = bboxs[vote_rank[0]]\n",
        "    # prob = result_prob[vote_rank[0]]\n",
        "    [c_x, c_y, w, h] = bbox_convert_r(bbox[0], bbox[1], bbox[2], bbox[3])\n",
        "    bboxs_2 = np.array([[c_x, c_y, w, h]])\n",
        "\n",
        "    pos_change = np.sqrt((label[0][0] - c_x) ** 2 + (label[0][1] - c_y) ** 2)\n",
        "    x_l, y_l, x_r, y_r = bbox_convert(label[0][0], label[0][1], label[0][2], label[0][3])\n",
        "    label_xxyy = [x_l, y_l, x_r, y_r]\n",
        "    # print(label[0])\n",
        "    # print(bboxs_2[0])\n",
        "    # print(pos_change)\n",
        "    if pos_change < 20 and IoU(bbox, label_xxyy) > 0.5:\n",
        "        object_in_class += 1\n",
        "    truth_in_class += 1\n",
        "\n",
        "accuracy = object_in_class / truth_in_class\n",
        "\n",
        "print('accuracy', accuracy)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "v2yLUbiNN3M-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## load the model\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = F110_YOLO()\n",
        "model_save_name = 'model_4_48.pt'\n",
        "path = F\"/content/drive/My Drive/ese516/{model_save_name}\"\n",
        "model.load_state_dict(torch.load(path))\n",
        "model = model.to(device)\n",
        "\n",
        "path = F\"/content/drive/My Drive/ese516/loss_4_48.npy\"\n",
        "loss = np.load(path, allow_pickle=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "slkXMrll3smY"
      }
    }
  ]
}